{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4 - Lorenzo Leuzzi\n",
        "\n",
        "DATASET (LERCIO HEADLINES) - Dataset collected by Michele Cafagna\n",
        "\n",
        "Pick up one of the available implementations of the Char-RNN (e.g. implement1,  implement2,  implement3, implement4, etc.) and train it on the dataset which contains about 6500 headlines from the Lercio satirical newspage, scraped by Michele Cafagna, past student of the ISPR course. The dataset is contained in a CSV file, one line per headlines. Be aware that the dataset can be a bit noisy (some errors due to encoding conversions) so you might need some preprocessing in order to prepare it for the task. Also, I am afraid the dataset is in Italian only as this is the language of the newspage.\n",
        "\n",
        "Try experimenting with different configurations of the CHAR-RNN, varying the number of layers. Since the dataset is quite small, keep the number of hidden neurons contained otherwise the net will overfit. Use the trained model (the best or the worst, your choice) to generate new headlines.  \n",
        "\n",
        "The softmax has a temperature parameter T that you can use to control the randomness of the output distribution (i.e. output logits are divided by T). Experiment with different values of T and comment the results."
      ],
      "metadata": {
        "id": "ySs5QnylI4I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "uEC-caCOKH-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wosX8JNDIZWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67461431-cba0-4998-ddb9-72901510a2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXP5LjDi5kD4",
        "outputId": "f1dbe6cc-6110-4583-9c0e-32711eb281fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/ispr/lercio_headlines.csv\""
      ],
      "metadata": {
        "id": "vXraNLHf5XeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a list of headlines\n",
        "headlines = []\n",
        "with open(DATASET_PATH, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    headlines = [row[0] for row in reader]"
      ],
      "metadata": {
        "id": "1lCo-kku8jE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8NjdWAW8ke1",
        "outputId": "f73ccfb8-40bb-4457-e6b8-ecbdca8a3f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nuovo slancio d’altruismo di Candreva: “Aiuterò Borja Valero ad attraversare la metà campo”',\n",
              " 'Tre bacini ma non passa la bua. Mamma denunciata per malasanità',\n",
              " 'Archeologia: nella prossima puntata Alberto Angela parlerà di altavista.com']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "UFJOQDWVQgR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **preprocess** our data we want to remove any duplicate headlines, remove any \"unreadble character\" and have all the headlines in lowercase."
      ],
      "metadata": {
        "id": "c91IyeXnRhNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate headlines\n",
        "headlines = list(set(headlines))\n",
        "\n",
        "# Remove non-ASCII characters from headlines\n",
        "for i in range(len(headlines)):\n",
        "    headlines[i] = unidecode.unidecode(headlines[i])\n",
        "\n",
        "# Convert all headlines to lowercase\n",
        "for i in range(len(headlines)):\n",
        "    headlines[i] = headlines[i].lower()"
      ],
      "metadata": {
        "id": "P33VNLci8mWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to train the Char-RNN, we're going to be feeding the input data in batches and have a complete headline for each pattern. If the headlines have different lengths, that is not possible. By **padding** the headlines to a fixed length, we can efficiently create batches data that have a fixed size and we are sure that the headlines are fed correctly into the network."
      ],
      "metadata": {
        "id": "ZFNRdYYoKSOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the maximum length for headlines\n",
        "max_length = len(max(headlines, key=len)) #168\n",
        "#print(max_length)\n",
        "# Define the padding character\n",
        "padding_char = '|' # char not present in any headline\n",
        "\n",
        "# Pad each headline to the maximum length\n",
        "for i in range(len(headlines)):\n",
        "    headline = headlines[i]\n",
        "    if len(headline) < max_length:\n",
        "        padding_length = max_length - len(headline)\n",
        "        padded_headline = headline + padding_char * padding_length\n",
        "        headlines[i] = padded_headline"
      ],
      "metadata": {
        "id": "yG65Hd7rJk2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlD0kJ4D8n94",
        "outputId": "bf0884b4-40b1-452c-bdd3-79b8ddd72615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"maestro elementare di scilipoti condannato per crimini contro l'umanita|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\",\n",
              " 'trump contro l\\'iniezione letale: \"troppo cara, la sostituiro con una sega arrugginita\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||',\n",
              " 'supermercato squalifica anziano per partenza anticipata|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_HEADLINES = len(headlines)\n",
        "print(N_HEADLINES)\n",
        "len(headlines[0]) #168 length of all the headlines after padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJaKDl0iV-WX",
        "outputId": "6b0f2bcb-5ea2-4af3-9142-cbe430cdc82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the preprocessed headlines into a **text file** to be consistent with the choosen implementation."
      ],
      "metadata": {
        "id": "pqRq12Lz7F_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('headlines.txt', 'w') as f:\n",
        "    for line in headlines:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "R66X7bF08qMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "UQbZLqjL63dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this [implementation](https://github.com/spro/char-rnn.pytorch) because it was the simplest to understand and it had all the necessary features needed. Here's the **CharRNN** model definition."
      ],
      "metadata": {
        "id": "bBUxRZZtSxtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.model = model.lower()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        if self.model == \"gru\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        elif self.model == \"lstm\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        batch_size = input.size(0)\n",
        "        encoded = self.encoder(input)\n",
        "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
        "        output = self.decoder(output.view(batch_size, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def forward2(self, input, hidden):\n",
        "        encoded = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.model == \"lstm\":\n",
        "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
        "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
        "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ],
      "metadata": {
        "id": "GNlwtLmm5-AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "gBMESyoW67rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility functions"
      ],
      "metadata": {
        "id": "XdlabqHdTWgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Readable time elapsed\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "metadata": {
        "id": "fCuxEDwr7koo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(decoder, name):\n",
        "    #save_filename = os.path.splitext(os.path.basename(args.filename))[0] + '.pt'\n",
        "    save_filename = f'/content/drive/MyDrive/ispr/{name}.pt'\n",
        "    torch.save(decoder, save_filename)\n",
        "    print('Saved as %s' % save_filename)"
      ],
      "metadata": {
        "id": "H9MZUm846O_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "    file = unidecode.unidecode(open(filename).read())\n",
        "    return file"
      ],
      "metadata": {
        "id": "tbg7nrDq7epi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning a string into a tensor\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        except:\n",
        "            continue\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "PNcRNJyo7hQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In training a Char-RNN model, we typically do not feed the entire training dataset to the model in a single epoch. Instead, we break the dataset into smaller **chunks** of size `batch_size`, and randomly sample one of these chunks at each epoch. This ensures that the model is exposed to a diverse range of examples and reduces the time required for training."
      ],
      "metadata": {
        "id": "YEH5RupQTkfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set(chunk_len, batch_size):\n",
        "    inp = torch.LongTensor(batch_size, chunk_len)\n",
        "    target = torch.LongTensor(batch_size, chunk_len)\n",
        "    for batch_i in range(batch_size):\n",
        "        random_hd_id = random.randint(0, N_HEADLINES-1)\n",
        "        start_index = random_hd_id * (chunk_len + 1)\n",
        "\n",
        "        end_index = start_index + chunk_len + 1\n",
        "        chunk = file[start_index:end_index]\n",
        "\n",
        "        try:\n",
        "          inp[batch_i] = char_tensor(chunk[:-1])\n",
        "          target[batch_i] = char_tensor(chunk[1:])\n",
        "        except RuntimeError: # to understand which headline caused problems\n",
        "          print(random_hd_id)\n",
        "          print(f\"{start_index}: {chunk}\")\n",
        "\n",
        "    inp = Variable(inp)\n",
        "    target = Variable(target)\n",
        "\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "AOb0CqNpAxdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate"
      ],
      "metadata": {
        "id": "ltaoNkLnV7cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to generate text **predictions** from a trained Char-RNN decoder model."
      ],
      "metadata": {
        "id": "q9rm52GkVQy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(decoder, prime_str='a', predict_len=169, temperature=0.8):\n",
        "    hidden = decoder.init_hidden(1)\n",
        "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\n",
        "\n",
        "    inp = prime_input[:,-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "\n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
        "\n",
        "    return predicted"
      ],
      "metadata": {
        "id": "b18pGns76HjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run training"
      ],
      "metadata": {
        "id": "kLkgTw3xWAqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read the data from the previously created text file."
      ],
      "metadata": {
        "id": "dSZlmf9wVXJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading and un-unicode-encoding data\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = read_file(\"headlines.txt\")\n",
        "print(file[:168]) # show an headline"
      ],
      "metadata": {
        "id": "iHvCQT2x6Sym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8219c5cc-a318-483c-f5bc-d1bd66d84cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maestro elementare di scilipoti condannato per crimini contro l'umanita|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(n_layers = 1, n_epochs = 1000, batch_size = 128):\n",
        "  chunk_len = max_length\n",
        "  print(chunk_len)\n",
        "\n",
        "  # Initialize models\n",
        "  hidden_size = 70\n",
        "  model_type = \"gru\"\n",
        "\n",
        "  learning_rate = 0.01\n",
        "  decoder = CharRNN(\n",
        "      n_characters,\n",
        "      hidden_size,\n",
        "      n_characters,\n",
        "      model_type,\n",
        "      n_layers=n_layers\n",
        "  )\n",
        "\n",
        "  decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  def train_step(inp, target):\n",
        "    hidden = decoder.init_hidden(batch_size)\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len-1):\n",
        "        output, hidden = decoder(inp[:,c], hidden)\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data / chunk_len\n",
        "\n",
        "\n",
        "  start = time.time()\n",
        "  all_losses = []\n",
        "  loss_avg = 0\n",
        "\n",
        "  # Start training\n",
        "  try:\n",
        "      print(\"Training for %d epochs...\" % n_epochs)\n",
        "      for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "          loss = train_step(*random_training_set(chunk_len, batch_size))\n",
        "          loss_avg += loss\n",
        "\n",
        "          if epoch % 100 == 0:\n",
        "              print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "              print(generate(decoder), '\\n')\n",
        "\n",
        "      print(\"Saving...\")\n",
        "      save(decoder, f\"char-rnn{n_layers}\")\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "      print(\"Saving before quit...\")\n",
        "      save(decoder, f\"char-rnn{n_layers}\")"
      ],
      "metadata": {
        "id": "oamAwghN87oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we run different experiments varying the number of hidden layers. When the training is finished the models are saved in my drive."
      ],
      "metadata": {
        "id": "KCQF5JyaVgWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(n_layers = 1, n_epochs = 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruF3BkDFDrrG",
        "outputId": "e2ba84cb-e606-440b-fb39-73f20295ff2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "168\n",
            "Training for 2000 epochs...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [01:07<20:10,  1.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1m 7s (100 5%) 0.9169]\n",
            "a cambora i la in appalionaa|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [02:15<19:10,  1.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2m 15s (200 10%) 0.8096]\n",
            "azza e angiera da ritica del cresa brocersi appo depettona di casa il passi||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [03:24<18:21,  1.54it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3m 24s (300 15%) 0.8080]\n",
            "arvoliano conco sara syarrivati che annomenti a govera a gatto|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [04:32<18:53,  1.41it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4m 32s (400 20%) 0.7435]\n",
            "ammetto capare il facato autose, acceparto e semprateo del morne|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [05:41<22:09,  1.13it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5m 41s (500 25%) 0.7827]\n",
            "arrichetta|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [06:48<14:50,  1.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6m 48s (600 30%) 0.7627]\n",
            "anderivare in i cancia gli stamino batterio bie del mollo e gratto di bembia|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [07:55<13:32,  1.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7m 55s (700 35%) 0.7544]\n",
            "alfarizioni di biesta video per vendono difesso a solo in tarito della serpondini: \"onedia\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 800/2000 [09:01<12:36,  1.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9m 1s (800 40%) 0.7537]\n",
            "al prima l'agosa esera in morme non rede testa non rifiua a fillitico che con mulora di nuovo firaco|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 900/2000 [10:08<11:53,  1.54it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10m 8s (900 45%) 0.7269]\n",
            "applica antrone il malse stata il pagato paporto in contro del maniche per centito|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1000/2000 [11:15<10:24,  1.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11m 15s (1000 50%) 0.7219]\n",
            "allo la dise ne altro che accusa celettore salvada piu reride coloro|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1100/2000 [12:22<10:05,  1.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12m 22s (1100 55%) 0.7136]\n",
            "argia, giulatore la: \"posto\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1200/2000 [13:28<08:40,  1.54it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13m 28s (1200 60%) 0.7219]\n",
            "all'ascennete, prostrafmi chiena esce a nera il bossi||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1300/2000 [14:35<07:18,  1.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14m 35s (1300 65%) 0.6972]\n",
            "artiea risparlo in espertata di veggentata della figlio del pil video la lecazione|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1400/2000 [15:42<06:17,  1.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15m 42s (1400 70%) 0.7011]\n",
            "attenzione: batta di magliano' e smettore dopo macchina||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1500/2000 [16:48<05:12,  1.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16m 48s (1500 75%) 0.7041]\n",
            "alle la scosa sciuno bambola compratorie in colpo in bugne|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1600/2000 [17:55<04:13,  1.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17m 55s (1600 80%) 0.6935]\n",
            "al posco che avanti una nuovo lo scoperare l'ambera alla guardiame di contro la farno per renza del padrone||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1700/2000 [19:02<03:08,  1.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19m 1s (1700 85%) 0.7277]\n",
            "ascrocce ascolta le matera per corsa si anni e si avere vitalia ai mercato ai zullo poliziati per incrosce di fare la fine dei marsa|||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1800/2000 [20:08<02:05,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20m 8s (1800 90%) 0.7196]\n",
            "artive ai nuovo viscinisti in un rifetto del trimanche di sponte|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1900/2000 [21:15<01:04,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21m 15s (1900 95%) 0.6873]\n",
            "andhia per riempresturista di emenelata a cacce un altre di salosita|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [22:22<00:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22m 21s (2000 100%) 0.7279]\n",
            "arrifo di casario da solo berluscone automula la maio del busta si una scosoni|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n",
            "Saving...\n",
            "Saved as /content/drive/MyDrive/ispr/char-rnn1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(n_layers = 2, n_epochs = 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5_LZds5TKqF",
        "outputId": "56ae5e6b-6ecc-492f-b1d6-cb67f6a04c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168\n",
            "Training for 2000 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 100/2000 [01:28<32:49,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1m 28s (100 5%) 0.9519]\n",
            "ar oconbi con il silca nesza li malecer cala siosto, inni dla malina della per parcettera |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 200/2000 [02:57<28:03,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2m 57s (200 10%) 0.8768]\n",
            "a, ablotto nell'ancordi labbbullo in 310co la mariana l'ardisi sulli minato||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 300/2000 [04:26<24:40,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4m 26s (300 15%) 0.7674]\n",
            "anchista dall'anora di megge della segratato da piu perne||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 400/2000 [05:53<22:15,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5m 53s (400 20%) 0.7607]\n",
            "anitarizza buo 2070: tito l'asseggette candaco seasa\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 500/2000 [07:22<21:38,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7m 22s (500 25%) 0.7719]\n",
            "angordina di fare su salvini|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 600/2000 [08:52<24:08,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8m 51s (600 30%) 0.7096]\n",
            "assini ossica in 2016, si contro in une si suona vi si fa solo dalla si lascia di bacce||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 700/2000 [10:20<19:38,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10m 20s (700 35%) 0.6837]\n",
            "ad lancia banco la sua vince di turdello e raddio di mergo|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 800/2000 [11:47<16:47,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11m 47s (800 40%) 0.7149]\n",
            "allessi mano giazza: sfilale di salima, i fondriato il propa|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 900/2000 [13:15<15:03,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13m 15s (900 45%) 0.6857]\n",
            "avragli consegna atto dei grillino in inva tra battare in incontra testimonio||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1000/2000 [14:43<14:46,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14m 43s (1000 50%) 0.6794]\n",
            "arrivo stagai di finisho scopre a san arrivo la testa di chiedio di \"abbialesi\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 1100/2000 [16:12<16:19,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16m 12s (1100 55%) 0.6745]\n",
            "apre conferma ritala: mangiato su radio2 kiggio scappalloni di un guare||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1200/2000 [17:40<11:47,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17m 40s (1200 60%) 0.6718]\n",
            "ancini finisce la schia rotte di ore apre il tasso di studi invigente a boom e strazie|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1300/2000 [19:08<09:42,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19m 8s (1300 65%) 0.6520]\n",
            "ax spista sulla fare le la sicore di partita che un abbraccio da consigat||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1400/2000 [20:36<08:21,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20m 36s (1400 70%) 0.6488]\n",
            "altavia senza danno ancora leganda di un libro e ome facebook del pace ma chirurgo dalla mista|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 1500/2000 [22:04<07:35,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22m 3s (1500 75%) 0.6532]\n",
            "annuncia matto di ritrova potrarme di applaggia||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 1600/2000 [23:33<07:09,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23m 33s (1600 80%) 0.6566]\n",
            "a si pagata male dimentica lui il puo che tato a gruppo in moglieste in capp di altro maro|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 1700/2000 [25:00<04:33,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25m 0s (1700 85%) 0.6332]\n",
            "amatoria arriva arestituisce spettare malsaniri se l'abbiamo di lay: \"abbranica di mastiturmiano\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1800/2000 [26:28<02:46,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26m 28s (1800 90%) 0.6185]\n",
            "accouro di la legis lercio: \"si commiato nel ceulocio cassa\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1900/2000 [27:56<01:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27m 56s (1900 95%) 0.6402]\n",
            "andro faranno una caglore ma al candeva ammaiso per riallo con piu faccia la compure|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [29:25<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29m 25s (2000 100%) 0.6588]\n",
            "altroma lo stragia: \"nagone in cui non ci mandare\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n",
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved as /content/drive/MyDrive/ispr/char-rnn2.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(n_layers = 3, n_epochs = 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSqZNDQ7TLqJ",
        "outputId": "73ccfa33-06e5-4167-ceeb-f8200ae40997"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "168\n",
            "Training for 2000 epochs...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [02:02<42:08,  1.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2m 2s (100 5%) 0.9772]\n",
            "acpiu selanre ptutarto gesFmissigii serio damalo nuantri pellotii ti dera per dearre soro sha nolresto|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [04:00<33:09,  1.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4m 0s (200 10%) 0.8363]\n",
            "amende daglo mere in miloekta di lencie su vendese al feole incina dell alita cenze di nefcieni greda e cuone||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [05:57<35:38,  1.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5m 57s (300 15%) 0.8124]\n",
            "attosiva il commrice sciale del levale a ripliata a calle: cambentista di gounzioni parlani||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [07:54<29:58,  1.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7m 54s (400 20%) 0.7513]\n",
            "alla spartata il baggia di remo della marticata a porde||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [09:51<30:03,  1.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9m 51s (500 25%) 0.7553]\n",
            "atticare il 2600 dal coleo corgeno un coporzolo dei costrippe di scolari|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [11:47<25:38,  1.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11m 47s (600 30%) 0.7161]\n",
            "alas: \"si assi punta la taberale ameriamo, goglio tra assabbo anni sono regale|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [13:49<24:05,  1.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13m 49s (700 35%) 0.6901]\n",
            "arriva scafera per stava con il gredio dei sinfiga i cotenti\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 800/2000 [15:45<28:01,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15m 45s (800 40%) 0.6741]\n",
            "arriva accarto e dimettere: sull'acchosi sing al marco con ma sessioni la sua pisirche|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 900/2000 [17:41<20:48,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17m 41s (900 45%) 0.6482]\n",
            "apparmergenza di tre ai talle della foccate per in madonna|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1000/2000 [19:37<21:49,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19m 37s (1000 50%) 0.6519]\n",
            "andruta della scamazioni sara rivela: \"cantato dal trandono gli scatta i trimotte\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 1100/2000 [21:33<17:23,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21m 33s (1100 55%) 0.6460]\n",
            "accondo scompatto in artime in camma di maio|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1200/2000 [23:28<15:45,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23m 28s (1200 60%) 0.6734]\n",
            "astronotta scritta gli aiatori del pd altro pestico e diga|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1300/2000 [25:25<13:41,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25m 25s (1300 65%) 0.6279]\n",
            "allata chiama l'ora che nascorgia i faccia le barce per massiamenti||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1400/2000 [27:20<10:51,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27m 20s (1400 70%) 0.6451]\n",
            "amente al film conte caus: \"antivolo! per decreto di cassia, compra di bissione\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 1500/2000 [29:17<09:52,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29m 17s (1500 75%) 0.6151]\n",
            "agdira scanzita anegrazione a una mano per quartare la visita non arriva|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 1600/2000 [31:13<07:13,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31m 13s (1600 80%) 0.6074]\n",
            "altori testi che vince il buco di comportazioni mangiare il selfico dell'inperrata e tra mangiare un web|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 1700/2000 [33:11<05:47,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33m 11s (1700 85%) 0.6062]\n",
            "al loin nuovo soio l'app infiglia di riporta aduzza||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1800/2000 [35:06<03:43,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[35m 6s (1800 90%) 0.6556]\n",
            "antivoloyon di porta due incinlitati di renzi di stavolyaly aurica contenano dalla santa chiede di accusaggio||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1900/2000 [37:03<01:58,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37m 3s (1900 95%) 0.5920]\n",
            "allarme, scopre conferma: vendono il confesso di puti mi se luzie||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [38:58<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38m 58s (2000 100%) 0.6217]\n",
            "aleni brasi la verda dalvale con sindario in artamia a casa in un cavologo di eorico in barza di mondiali di poteri non 10|||||||||||||||||||||||||||||||||||||||||||||||| \n",
            "\n",
            "Saving...\n",
            "Saved as /content/drive/MyDrive/ispr/char-rnn3.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the different models"
      ],
      "metadata": {
        "id": "V7jNdaFDTyHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now test the different models generating headlines."
      ],
      "metadata": {
        "id": "vDJ052aoWZug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prime_examples = [\"scoperto\", \"oggi\", \"attacco\", \"due\", \"forza\", \"il\", \"uomo\", \"donna\", \"ritrovato\", \"governo\", \"salvini\"]\n",
        "predicted_headlines = []\n",
        "\n",
        "for i in range(1, 4):\n",
        "  model = f'/content/drive/MyDrive/ispr/char-rnn{i}.pt'\n",
        "  decoder = torch.load(model)\n",
        "  for prime in prime_examples:\n",
        "    predicted = generate(decoder, prime)\n",
        "    predicted_headlines.append(predicted.replace(\"|\", \"\"))"
      ],
      "metadata": {
        "id": "dF9u7-H0TX58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted headlines for the first model (1 hidden layer)"
      ],
      "metadata": {
        "id": "gwh8DMKeXFAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_headlines[:len(prime_examples)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZKxaPDtXEXW",
        "outputId": "48f5ba83-298a-494e-af0d-c60b53cf3faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scoperto al presetto di perto a maio solo a radio e a film costri fare incuita vota da una buone',\n",
              " \"oggi d'a medice e non resterchete dall'ancora indive la concermenio\",\n",
              " 'attacco diavano in camano il cuore allo giovanne',\n",
              " \"due a saranno tunivante di revista di torna in conestita: 'la prima i cascina a malice\",\n",
              " \"forza con che l'inventopegna dal 2019 non verdi a casa di capia di gioca\",\n",
              " 'il w70% il corrazzo a un lapollamentare: \"sono luitente del noalo tutalia del divorziamo di rittorizzista occupe\"',\n",
              " 'uomo nuovo verna avantico rivela: \"non scopista animarino all\\'ambita di complavapo\"',\n",
              " 'donna risara la mestice al confretto: grande solo nel boccone. ai girette ascoltare cucle',\n",
              " 'ritrovato infarto trova la chinestrilizione oratica la assetta finanza incidente dal 2027',\n",
              " 'governo di vince a zodiarga il contro per scopatifono essere a magione da stato a renzi da miliandi ma il caporali',\n",
              " 'salvini fa \"l\\'arrivo farato di mentata il paganzante dal morte della traduse chimica di trancio\"']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted headlines for the second model (2 hidden layers)"
      ],
      "metadata": {
        "id": "BTnX95C6XhED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_headlines[len(prime_examples):len(prime_examples)*2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ohPhO12XSmF",
        "outputId": "d7fd03f4-07a6-4baa-a4ed-0092909a39ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"scoperto padre non prende il capiscole svando che lo spazzetta del palinon si non esarire l'esporta all'all'estotivissione\",\n",
              " 'oggiusta preceden attide alle arrestato in mangia e il fermio e un altro gli scienziati',\n",
              " 'attacco, la collano a era volte gial alberi: \"ci chianno i genistri di notti e il progestimo\"',\n",
              " 'due camina con gli preneare i ciolizzato: \"ai nei finici e credeva imali\"',\n",
              " 'forzato gattina, ritrova rai dice di maggia',\n",
              " 'il mio: \"basti si ancorn disara per chiede l\\'alt al mondo di cardi\"',\n",
              " 'uomo. \"tracqua al regoli per i potremo la dura le fabbrica\"',\n",
              " 'donna bagno al pizzica il pace di chachia e fa riservie mondiale',\n",
              " 'ritrovatore \"rischus accusa delle salute mesi\": 2 reddito di seritarno di terre del mondo cieli',\n",
              " 'governo, alle costi come matte la mostra e fa esclusa esimisco e fa aderantini',\n",
              " \"salvini anche il raccone gara la maggiorna a mente sono avvici in un contro l'uoma\"]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted headlines for the third model (3 hidden layers)"
      ],
      "metadata": {
        "id": "_5G5jJDDXhnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_headlines[len(prime_examples)*2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF1AERgwXYh6",
        "outputId": "8161f133-ca07-4ff8-f8c0-643861f720a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scoperto ua sciolzare mi emeratori al parente cazzata intretta: storato su chavorico',\n",
              " 'oggio la famiglia in parranza a gresi, suicidio veloce di sue mese del marito di applaus',\n",
              " 'attacco di adotare 10 mesi: \"odianna a 2 chi per stueomi della votano fencere\"',\n",
              " 'due confessa: \"mi affancati andato al corona fa vedono sempre il goccorsare e fa un\\'orare la ravermausa\"',\n",
              " \"forza esaganti tanti compra chiedere il profogorione dell'occhione e per il discotaro porta\",\n",
              " 'il paglia a un matrimonio omicidio di arrestata ma era guarisce banca',\n",
              " 'uomo detta dal carcarestato 12 oreli di fine mondiale del mello di bari',\n",
              " 'donna impossione in stato cerca anche sessuale e i visiti',\n",
              " 'ritrovato il nuovo portico signotero le ricchi di mercanno su un sclater',\n",
              " 'governo uccide la barca di processare le elezioni in 10mpra di mariatore',\n",
              " 'salvini: \"troppi meno dovra il tuo degli rotti?\" per cosa vieta che giovane ottiene il primo bumminato 6']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this examples it is not clear which model generates  better headlines (the third one might have a slight edge). Considering the training losses, the third model has the lowest value so we are going to choose it for the next section."
      ],
      "metadata": {
        "id": "mf1S5L7TfVuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimenting with temperature"
      ],
      "metadata": {
        "id": "BAsGCh3XaPhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now experiment with different values of the softmax **temperature** parameter T that we can use to control the randomness of the output distribution."
      ],
      "metadata": {
        "id": "nnXajOmnegRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = f'/content/drive/MyDrive/ispr/char-rnn3.pt'\n",
        "best_decoder = torch.load(best_model)\n",
        "temperatures = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "predictions_t = []\n",
        "for t in temperatures:\n",
        "  predicted = generate(best_decoder, temperature=t)\n",
        "  predictions_t.append(predicted.replace(\"|\", \"\"))"
      ],
      "metadata": {
        "id": "Ah7b93H0aTtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are shown in ascending temperature value"
      ],
      "metadata": {
        "id": "kLXWxS0Cxgt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0LGo_8PbR9w",
        "outputId": "ed1e0d4d-791e-4880-8759-ec83c9bdeacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arriva la mano in italia di maio e una sciolda di arrestato da un mese per le compagni di santani',\n",
              " 'allarme della lava a discorso dal carcere delle col commento di maio in compagno',\n",
              " 'allarme del mondo al giorno per aver per i casalesi malieri alle spadani',\n",
              " \"allarme scopre che l'omosessuale e dovemo merca le foto di parenti all'autobilitato\",\n",
              " 'arriva le mano al 2016 la famiglia di annuncia la testa comita il gastico del sedita di studio di prossimo di maria',\n",
              " \"alfarme del con confossare che sbaglia l'italia e per bambine\",\n",
              " 'arriva le lavora il masilo di fedele di fermatella fisica',\n",
              " \"also finisce internamiane su scopre che l'avemlas che non la fina dall'etremerisce a servi\"]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this results we can say that model generates more understandable headlines with lower values of the temperature parameter (0.3-0.5)."
      ],
      "metadata": {
        "id": "N6CcSt8adD9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_predictions = []\n",
        "for prime in prime_examples:\n",
        "   predicted = generate(best_decoder, prime, temperature=0.35)\n",
        "   best_predictions.append(predicted.replace(\"|\", \"\"))\n",
        "\n",
        "best_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Dp2yx7ddGM",
        "outputId": "2184f5e1-e88f-44ac-bc76-8abc0c7424f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scoperto il primo stato di colore per stagione e viene alla fila di roma',\n",
              " 'oggiara di cambia le confessa: \"il bambino della parte del figlio per le strade di maio\"',\n",
              " 'attacco di casa il mare di allevica per un commedio alle coppie in stato di euro per amare il mondo',\n",
              " 'due mangia il cancella piu per dare i calcio di giorni alle come scopre che si fa la scheda',\n",
              " \"forza scambia la madre all'ario a sosteneva e scopre di appendiamo alla paga\",\n",
              " 'il redazione si fa il prossimo alle completario e viene il primo contro male',\n",
              " 'uomo paralico di corre di marie al commedista del mondo di salvini annuncia',\n",
              " 'donna alla scarabilita di san solo una parte della barbona di maio alle mani di essere il mercato della fabio',\n",
              " 'ritrovato il prossimo solo un cancella per le copie della parte e la pancia se scanzi a fare il campo di saranno al giorno di correr',\n",
              " 'governo il capo di compassano il primo maggio a un confondo dopo le porta di vero',\n",
              " 'salvini si compra le come solo in servizio e muore in col cazzo di maio']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions"
      ],
      "metadata": {
        "id": "8r6lg3W7hSfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the studying and the exploration of Recurrent Neural Networks, specifically the Char-RNN model, I found the experience to be both engaging and intriguing. Being a deep learning model, it has the potential to create new text data, and it was fascinating to observe how the model was able to partially learn and comprehend the patterns and structure of the original dataset to generate new text sequences. While the generated headlines were not entirely credible, they did reflect the satirical and comedic aspects of the original dataset (*Lercio*), which was a noticeable outcome."
      ],
      "metadata": {
        "id": "743dtq5ThV8B"
      }
    }
  ]
}